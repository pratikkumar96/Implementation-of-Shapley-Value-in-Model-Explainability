# Implementation-of-Shapley-Value-in-Model-Explainability
To discuss the concept of Shapley value for feature interpretability and complex model explainability

Shapley value is an important concept originating from "Game Theory" which helps us to understand the importance of each feature in Model Prediction. It highlights the contributions of features in pushing the probability of a particular obseravtion towards the positive or negative diection of mean probability. For GLM models, we can understand this through the beta values but it becomes a bit hard for Complex models like tree based models and deep learning models. 
